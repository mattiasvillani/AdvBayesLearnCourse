#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 11
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 0
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 0
\use_package mhchem 1
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2.5cm
\topmargin 2.5cm
\rightmargin 2.5cm
\bottommargin 2.5cm
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\noindent
\align left
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="3">
<features tabularvalignment="middle">
<column alignment="left" valignment="top">
<column alignment="left" valignment="top">
<column alignment="right" valignment="top">
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Mattias Villani
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset space \hspace{}
\length 5.3cm
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Advanced Bayesian Learning, 2024
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Department of Statistics
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Stockholm University
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace 0.3cm
\end_inset


\end_layout

\begin_layout Standard
\noindent
\align left
\begin_inset Tabular
<lyxtabular version="3" rows="6" columns="1">
<features tabularvalignment="middle">
<column alignment="left" valignment="top">
<row>
<cell multicolumn="1" alignment="none" valignment="top" usebox="none" special="l">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\size large
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{}
\end_layout

\end_inset

Computer Lab 4 - Regularization and Variable Selection
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multicolumn="1" alignment="none" valignment="top" usebox="none" special="l">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset line
LatexCommand rule
width "97.5col%"
height "1pt"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell multicolumn="1" alignment="none" valignment="top" usebox="none" special="l">
\begin_inset Text

\begin_layout Plain Layout
The labs are the only examination, so you should do the labs 
\series bold
individually
\series default
.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multicolumn="1" alignment="none" valignment="top" usebox="none" special="l">
\begin_inset Text

\begin_layout Plain Layout
You can use any programming language you prefer, but do 
\series bold
submit the code
\series default
.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Submit a readable report in 
\series bold
PDF
\series default
 (no Word documents!) or a 
\series bold
JuPyteR notebook
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multicolumn="1" alignment="none" valignment="top" usebox="none" special="l">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset line
LatexCommand rule
width "97.5col%"
height "1pt"

\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard

\size footnotesize
\begin_inset VSpace 0.5cm
\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace 0.3cm
\end_inset


\end_layout

\begin_layout Standard
In this lab you will use the prostate cancer dataset from the book 
\begin_inset CommandInset href
LatexCommand href
name "Elements of Statistical Learning"
target "https://hastie.su.domains/ElemStatLearn/printings/ESLII_print12_toc.pdf"
literal "false"

\end_inset

 (ESLII, see Section 3.2.1 for a description of the dataset and the regression
 model setup).
 The dataset can be downloaded here: 
\begin_inset CommandInset href
LatexCommand href
name "prostate cancer data"
target "https://hastie.su.domains/ElemStatLearn/datasets/prostate.data"
literal "false"

\end_inset

.
 Use the same model as in ESLII:
\begin_inset Formula 
\[
\texttt{lpsa}=\beta_{0}+\beta_{1}\texttt{lcavol}+\beta_{2}\texttt{lweight}+\beta_{3}\texttt{age}+\beta_{4}\texttt{lbph}+\beta_{5}\texttt{svi}+\beta_{6}\texttt{lcp}+\beta_{7}\texttt{gleason}+\beta_{8}\texttt{pgg45}
\]

\end_inset

with 
\begin_inset Formula $\varepsilon\overset{\mathrm{iid}}{\sim}N(0,\sigma^{2})$
\end_inset

.
 Use all 97 observations in the dataset (note that the ESLII book uses a
 random sample of observations for training).
 Standardize the covariates to have zero mean and unit variance.
 
\size footnotesize

\begin_inset VSpace 0.5cm
\end_inset


\end_layout

\begin_layout Enumerate

\series bold
Bayesian regularization
\series default
.
 The linear regression model with a iid Gaussian (L2-regularization) prior
 is
\begin_inset Formula 
\begin{align*}
y_{i} & =\beta_{0}+\boldsymbol{x}_{i}^{\top}\boldsymbol{\beta}+\varepsilon_{i},\qquad\varepsilon_{i}\overset{\mathrm{iid}}{\sim}N(0,\sigma^{2})\\
\boldsymbol{\beta}\vert\sigma^{2},\lambda & \sim N\left(\boldsymbol{0},\frac{\sigma^{2}}{\lambda}I_{p}\right)\\
\sigma^{2} & \sim\mathsf{Inv}-\chi^{2}\left(\nu_{0},\sigma_{0}^{2}\right)\\
\lambda^{-1}=\psi^{2} & \sim\mathsf{Inv}-\chi^{2}\left(\omega_{0},\psi_{0}^{2}\right)
\end{align*}

\end_inset

and we use a non-informative 
\begin_inset Formula $\beta_{0}\vert\sigma^{2}\sim N(0,100^{2}\sigma^{2})$
\end_inset

 prior for the intercept.
\end_layout

\begin_deeper
\begin_layout Enumerate
You can use 
\begin_inset CommandInset href
LatexCommand href
name "my implementations of the Gibbs sampler"
target "https://mattiasvillani.com/BayesianLearningBook/code.html"
literal "false"

\end_inset

 in Julia and R for sampling from the posterior 
\begin_inset Formula $p(\beta_{0},\boldsymbol{\beta},\sigma^{2},\lambda\vert\boldsymbol{y},\boldsymbol{X})$
\end_inset

 [If you are a Pythonista, ask chatGPT to translate the code and check for
 correctness.].
 Use the sampler to analyze the prostate cancer dataset.
 Set the prior hyperparameters to 
\begin_inset Formula $\nu_{0}=0.01$
\end_inset

 and 
\begin_inset Formula $\sigma_{0}^{2}=1$
\end_inset

, 
\begin_inset Formula $\omega_{0}=0.01$
\end_inset

 and 
\begin_inset Formula $\psi_{0}^{2}=1$
\end_inset

.
 Draw a posterior sample of 10000 draws (after a burn-in of 1000 draws)
 and present summaries of the results.
\end_layout

\begin_layout Enumerate
Explore if the posterior distribution of 
\begin_inset Formula $\lambda$
\end_inset

 and the elements of 
\begin_inset Formula $\boldsymbol{\beta}$
\end_inset

 are sensitive to the prior on 
\begin_inset Formula $\psi^{2}$
\end_inset

 by trying out at least two other values for 
\begin_inset Formula $\omega_{0}$
\end_inset

.
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Enumerate
Now use the horseshoe prior
\begin_inset Formula 
\begin{align*}
\beta_{j}\vert\sigma^{2},\lambda_{j}^{2},\tau^{2} & \sim N\left(0,\sigma^{2}\tau^{2}\lambda_{j}^{2}\right)\\
\lambda_{j} & \overset{\mathrm{iid}}{\sim}C^{+}(0,1)\\
\tau & \sim C^{+}(0,1)\\
\sigma^{2} & \sim\mathsf{Inv}-\chi^{2}\left(\nu_{0},\sigma_{0}^{2}\right)
\end{align*}

\end_inset

and the same non-informative 
\begin_inset Formula $\beta_{0}\vert\sigma^{2}\sim N(0,100^{2}\sigma^{2})$
\end_inset

 prior for the intercept.
 Implement the Gibbs sampling algorithm for the horseshoe prior described
 in the Section 
\emph on
Global-local regularization
\emph default
 
\emph on
and Horseshoe
\size footnotesize
\emph default
 
\size default
in the 
\begin_inset CommandInset href
LatexCommand href
name "Bayesian Learning book"
target "https://github.com/mattiasvillani/BayesianLearningBook/raw/main/pdf/BayesBook.pdf"
literal "false"

\end_inset

.
 Use this implementation to sample 10000 iterations (after a burn-in of
 1000 iterations) from the posterior 
\begin_inset Formula $p(\beta_{0},\boldsymbol{\beta},\sigma^{2},\tau\vert\boldsymbol{y},\boldsymbol{X})$
\end_inset

 for the prostate cancer dataset.
 Compare with the results from the L2-prior in 1a) and to the least squares
 estimate.
\end_layout

\begin_layout Enumerate
[
\series bold
Bonus question
\series default
 if you feel up to it, and know RStan or Turing.jl well (so that this is
 a quick thing for you).
 Sample the posterior for the regression with a horseshoe prior using RStan
 or Turing.jl.
 Compare the resulting posteriors from the Gibbs sampler and RStan/Turing.jl's
 HMC sampler.
 Compare effective sample size per second of computing time.
 Since RStan is coded in C++, your Python/R code for the Gibbs sampler will
 be slower.
 Julia is closer to C++ speed and my Julia implementation makes 
\begin_inset Formula $10000$
\end_inset

 draws in 0.3 seconds.
 Note also that my prior for 
\begin_inset Formula $\beta_{j}$
\end_inset

 has a variance scaled by 
\begin_inset Formula $\sigma^{2}$
\end_inset

, which is not always how other people do it (e.g.
 the original Horseshoe paper)].
\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
Bayesian variable selection
\end_layout

\begin_deeper
\begin_layout Enumerate
Implement Bayesian variable selection using the spike-and-slab prior, 
\series bold
or
\series default
 find a package in your favorite language that does it for you (I leave
 that choice up to you, depending on how much time you spent on Problem
 1 above and how useful variable selection is for your research).
 Analyze the prostate cancer data with prior hyperparameters 
\begin_inset Formula $\tau=10$
\end_inset

 and 
\begin_inset Formula $\omega=0.5$
\end_inset

.
 Explore how the posterior inclusion probabilities for the variables depend
 on the prior hyperparameter 
\begin_inset Formula $\tau$
\end_inset

.
 Try to explain the Bayesian logic behind these results.
\end_layout

\begin_layout Enumerate
The standard spike-and-slab prior uses the following prior for the binary
 selection indicators for the 
\begin_inset Formula $p$
\end_inset

 covariates:
\begin_inset Formula 
\[
z_{1},\ldots,z_{p}\vert\omega\sim\mathrm{Bernoulli}(\omega)
\]

\end_inset

and it is common to set 
\begin_inset Formula $\omega=0.5$
\end_inset

.
 What is the distribution on the number of covariates with non-zero regression
 coefficients? Would this always be a good prior?
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset VSpace bigskip
\end_inset

Good luck! 
\end_layout

\end_body
\end_document
